{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM MAE: 759286.1125521327\n",
      "LightGBM RMSE: 1261687.41461134\n",
      "LightGBM R2: 0.9195887043375472\n",
      "Epoch 1/30, Loss: 89770462019584.0000\n",
      "Epoch 2/30, Loss: 71559448363008.0000\n",
      "Epoch 3/30, Loss: 116234699931648.0000\n",
      "Epoch 4/30, Loss: 58691365634048.0000\n",
      "Epoch 5/30, Loss: 66565223481344.0000\n",
      "Epoch 6/30, Loss: 125182500929536.0000\n",
      "Epoch 7/30, Loss: 86437357682688.0000\n",
      "Epoch 8/30, Loss: 67739343388672.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 161\u001b[39m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m xb, yb \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[32m    160\u001b[39m     xb, yb = xb.to(device), yb.to(device)\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     pred = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m     loss = criterion(pred, yb)\n\u001b[32m    163\u001b[39m     optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ML/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import lightgbm as lgb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# -----------------------------\n",
    "# 1. 配置与数据加载\n",
    "# -----------------------------\n",
    "DATA_PATH = './tube1.csv'  # 替换为实际文件路径\n",
    "MODES = ['f3', 'f4', 'f5']\n",
    "\n",
    "# 载入并清洗数据\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "features_to_clean = [f'f{i}' for i in range(7, 17)]\n",
    "for feat in features_to_clean:\n",
    "    df = df[df[feat] > 0]\n",
    "\n",
    "# 构建模式组合列\n",
    "df['mode'] = df[MODES].astype(str).agg('-'.join, axis=1)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. 拐点检测 + RUL 标签构建\n",
    "# -----------------------------\n",
    "def detect_knee_point(time, signal, window=5):\n",
    "    # 简易二阶导数峰值检测\n",
    "    dy = np.gradient(signal)\n",
    "    ddy = np.gradient(dy)\n",
    "    idx = np.argmax(np.abs(ddy))\n",
    "    return time[idx]\n",
    "\n",
    "records = []\n",
    "for mode, group in df.groupby('mode'):\n",
    "    group = group.sort_values('f1').reset_index(drop=True)\n",
    "    t = group['f1'].values\n",
    "    f9 = group['f9'].values\n",
    "    knee_t = detect_knee_point(t, f9)\n",
    "    end_t = t[-1]\n",
    "    # 计算 RUL\n",
    "    group['RUL'] = end_t - group['f1']\n",
    "    records.append(group)\n",
    "\n",
    "df_labeled = pd.concat(records).reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. 特征工程（ML vs DL）\n",
    "# -----------------------------\n",
    "# 公共：模式独热（新参数 sparse_output=False）\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "mode_ohe = encoder.fit_transform(df_labeled[['mode']])\n",
    "mode_cols = encoder.get_feature_names_out(['mode'])\n",
    "df_modes = pd.DataFrame(mode_ohe, columns=mode_cols, index=df_labeled.index)\n",
    "\n",
    "# 数值特征：f9 当前值 + 5步 rolling slope\n",
    "WINDOW = 5\n",
    "roll_slope = df_labeled['f9'].diff(WINDOW) / WINDOW\n",
    "df_feat = pd.DataFrame({\n",
    "    'f9': df_labeled['f9'],\n",
    "    'f9_slope': roll_slope.fillna(0)\n",
    "}, index=df_labeled.index)\n",
    "\n",
    "# 合并特征\n",
    "X = pd.concat([df_feat, df_modes], axis=1)\n",
    "y = df_labeled['RUL']\n",
    "\n",
    "# 归一化\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. 传统 ML: LightGBM 训练\n",
    "# -----------------------------\n",
    "lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, label=y_test, reference=lgb_train)\n",
    "\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': ['mae', 'rmse'],\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 31,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "gbm = lgb.train(\n",
    "    params,\n",
    "    lgb_train,\n",
    "    num_boost_round=200,\n",
    "    valid_sets=[lgb_train, lgb_eval]\n",
    ")\n",
    "\n",
    "# 评估\n",
    "y_pred_lgb = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "print(\"LightGBM MAE:\", mean_absolute_error(y_test, y_pred_lgb))\n",
    "print(\"LightGBM RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_lgb)))\n",
    "print(\"LightGBM R2:\", r2_score(y_test, y_pred_lgb))\n",
    "\n",
    "# -----------------------------\n",
    "# 5. 深度学习: LSTM 模型\n",
    "# -----------------------------\n",
    "SEQ_LEN = 30  # 序列长度\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 30\n",
    "\n",
    "# 构造序列数据集\n",
    "class RULDataset(Dataset):\n",
    "    def __init__(self, X, y, seq_len):\n",
    "        self.X = X\n",
    "        self.y = y.values\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y) - self.seq_len + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_seq = self.X[idx:idx+self.seq_len]\n",
    "        y_val = self.y[idx+self.seq_len-1]\n",
    "        return torch.tensor(x_seq, dtype=torch.float32), torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "# 创建 DataLoader\n",
    "df_X_train = pd.DataFrame(X_train)\n",
    "df_y_train = pd.Series(y_train)\n",
    "df_X_test = pd.DataFrame(X_test)\n",
    "df_y_test = pd.Series(y_test)\n",
    "train_dataset = RULDataset(df_X_train.values, df_y_train, SEQ_LEN)\n",
    "test_dataset = RULDataset(df_X_test.values, df_y_test, SEQ_LEN)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# 定义 LSTM 回归模型\n",
    "class LSTMRegressor(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]\n",
    "        return self.fc(out).squeeze()\n",
    "\n",
    "# 初始化模型\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LSTMRegressor(input_dim=X_train.shape[1]).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 训练\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        pred = model(xb)\n",
    "        loss = criterion(pred, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# 测试\n",
    "model.eval()\n",
    "all_preds, all_targets = [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(device)\n",
    "        preds = model(xb).cpu().numpy()\n",
    "        all_preds.append(preds)\n",
    "        all_targets.append(yb.numpy())\n",
    "\n",
    "y_pred_lstm = np.concatenate(all_preds)\n",
    "y_true_lstm = np.concatenate(all_targets)\n",
    "print(\"LSTM MAE:\", mean_absolute_error(y_true_lstm, y_pred_lstm))\n",
    "print(\"LSTM RMSE:\", np.sqrt(mean_squared_error(y_true_lstm, y_pred_lstm)))\n",
    "print(\"LSTM R2:\", r2_score(y_true_lstm, y_pred_lstm))\n",
    "\n",
    "# -----------------------------\n",
    "# 6. 小结与对比\n",
    "# -----------------------------\n",
    "# 可根据输出的 MAE/RMSE/R2 指标比较两种方法的表现，并进行后续调优。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ML/lib/python3.13/site-packages/sklearn/base.py:1389: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (3). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['f9_slope'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# 原 mode 可保留或删除，此处后续将使用 sub_mode 做独热编码\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mode, group \u001b[38;5;129;01min\u001b[39;00m df.groupby(\u001b[33m'\u001b[39m\u001b[33mmode\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     X_mode = \u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mf9\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mf9_slope\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m.values\n\u001b[32m     50\u001b[39m     pca = PCA(n_components=\u001b[32m2\u001b[39m)\n\u001b[32m     51\u001b[39m     coords = pca.fit_transform(X_mode)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ML/lib/python3.13/site-packages/pandas/core/frame.py:4108\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4107\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4108\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4110\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ML/lib/python3.13/site-packages/pandas/core/indexes/base.py:6200\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6198\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6200\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6202\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6204\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ML/lib/python3.13/site-packages/pandas/core/indexes/base.py:6252\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6249\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6251\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6252\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['f9_slope'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "# 假设已有 DataFrame df，包括 'mode'、'f9' 等列\n",
    "# df = pd.read_csv('data.csv')  # 读取示例数据\n",
    "DATA_PATH = './tube1.csv'  # 替换为实际文件路径\n",
    "MODES = ['f3', 'f4', 'f5']\n",
    "\n",
    "# 载入并清洗数据\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "features_to_clean = [f'f{i}' for i in range(7, 17)]\n",
    "for feat in features_to_clean:\n",
    "    df = df[df[feat] > 0]\n",
    "\n",
    "# 构建模式组合列\n",
    "df['mode'] = df[MODES].astype(str).agg('-'.join, axis=1)\n",
    "\n",
    "cluster_labels = []\n",
    "for mode, group in df.groupby('mode'):\n",
    "    X = group[['f9']].values.reshape(-1, 1)\n",
    "    best_n = 1\n",
    "    best_score = -1\n",
    "    best_labels = [0] * len(group)  # 如果只聚为1类，则所有标签为0\n",
    "    # 尝试 2 类和 3 类\n",
    "    for n_clusters in [2, 3]:\n",
    "        if len(X) >= n_clusters:\n",
    "            kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(X)\n",
    "            labels = kmeans.labels_\n",
    "            # 需要至少两个簇才能计算轮廓系数\n",
    "            if len(set(labels)) > 1:\n",
    "                score = silhouette_score(X, labels)\n",
    "            else:\n",
    "                score = -1\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_n = n_clusters\n",
    "                best_labels = labels\n",
    "    # 将结果填充回 cluster_labels 列表\n",
    "    cluster_labels.extend([f\"mode{mode}_c{lbl}\" for lbl in best_labels])\n",
    "# 将 sub_mode 列加入 df\n",
    "df['sub_mode'] = cluster_labels\n",
    "# 原 mode 可保留或删除，此处后续将使用 sub_mode 做独热编码\n",
    "\n",
    "df_encoded = pd.get_dummies(df, columns=['sub_mode'])\n",
    "# 假设 RUL 是要预测的目标变量\n",
    "features = ['f9', 'f9_slope'] + [col for col in df_encoded.columns if col.startswith('sub_mode_')]\n",
    "X = df_encoded[features]\n",
    "y = df_encoded['RUL']\n",
    "\n",
    "\n",
    "\n",
    "for mode, group in df.groupby('mode'):\n",
    "    X_mode = group[['f9', 'f9_slope']].values\n",
    "    pca = PCA(n_components=2)\n",
    "    coords = pca.fit_transform(X_mode)\n",
    "    labels = group['sub_mode'].astype('category').cat.codes\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.scatterplot(x=coords[:,0], y=coords[:,1], hue=group['sub_mode'], palette='tab10')\n",
    "    plt.title(f'Mode {mode} 的 f9 聚类分布 (PCA 投影)')\n",
    "    plt.xlabel('PCA 维度 1')\n",
    "    plt.ylabel('PCA 维度 2')\n",
    "    plt.legend(title='sub_mode')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'mode{mode}_pca_clusters.png')\n",
    "    plt.close()\n",
    "\n",
    "# 示例：每个 cluster 的 f9 vs 时间 曲线（平均趋势）\n",
    "df['time'] = df.groupby('sub_mode').cumcount()  # 假设每个 sub_mode 内时间连续\n",
    "df_mean = df.groupby(['sub_mode', 'time'])['f9'].mean().reset_index()\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.lineplot(data=df_mean, x='time', y='f9', hue='sub_mode', palette='tab10')\n",
    "plt.title('各 Cluster 平均 f9 随时间的退化趋势')\n",
    "plt.xlabel('时间')\n",
    "plt.ylabel('平均 f9')\n",
    "plt.legend(title='sub_mode')\n",
    "plt.tight_layout()\n",
    "plt.savefig('cluster_f9_vs_time.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
